dataset_paths:
  train: /home/remote_hdd/datasets_for_incremental_training/figer/complete/pretraining_train_nodev.json
  dev: /home/remote_hdd/datasets_for_incremental_training/figer/complete/pretraining_dev.json
  test: /home/remote_hdd/datasets_for_incremental_training/figer/complete/pretraining_test.json
tokenizer_params:
  name : MentionSentenceBERTTokenizedDataset
  bertlike_model_name: bert-large-cased
  max_mention_words: 6
  max_right_words: 19
  max_left_words: 19
  max_tokens: 80
rw_options:
  modality: Load # in [Create, CreateAndSave, Load]
  dirpath: /home/remote_hdd/tokenized_datasets/figer/specialization/pretraining
  light: True
  # types_list_path: TBD