{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create partitions for pretraining datasets and incremental datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "SEED = [0, 1, 2]\n",
    "# NOTE: to obtain the X-shot from the sota, set MIN_FREQ=2*X and TRAIN_RATIO=0.5\n",
    "MIN_FREQ = 40 # 10 20 40\n",
    "TRAIN_RATIO = 0.5\n",
    "# set main directories\n",
    "DATA = 'ontonotes_shimaoka' # bbn\n",
    "SCENARIO = 'complete' # ['complete', 'single_child']\n",
    "TRAIN_DATA = 'train.json'\n",
    "DEV_DATA = 'dev.json'\n",
    "TEST_DATA = f\"test{'-12k' if DATA == 'bbn' else ''}.json\"\n",
    "SRC_DATA_DIR = f'/home/remote_hdd/datasets_for_incremental_training/{DATA}/{SCENARIO}'\n",
    "# DST_DATA_DIR = os.path.expanduser(f'./{DATA}/complete')\n",
    "DST_DATA_DIR = f'/home/remote_hdd/datasets_for_incremental_training/{DATA}/{SCENARIO}_subset_{MIN_FREQ}'\n",
    "DST_DATA_DIR = os.path.join(DST_DATA_DIR, 'instance_{}')\n",
    "ONTOLOGY_PATH = f'/home/remote_hdd/datasets_for_incremental_training/{DATA}/all_types.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load ontology\n",
    "# type2id = utils.load_ontology(ONTOLOGY_PATH)\n",
    "# types = list(type2id.keys())\n",
    "# # create hierarchy tree\n",
    "# tree = utils.create_tree(ONTOLOGY_PATH)\n",
    "# tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train/dev partitions such that:\n",
    "- types with a training frequency < MIN_FREQ are excluded from the datasets\n",
    "- each incremental type has MIN_FREQ instances (example with 100: 80 train, 20 dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_transit/incremental_train_road.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:07,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_person_artist/incremental_train_music.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_person_artist/incremental_train_director.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_person_artist/incremental_train_actor.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_person_artist/incremental_train_author.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:00<00:01,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_product/incremental_train_weapon.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_product/incremental_train_car.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_product/incremental_train_computer.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_product/incremental_train_software.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_organization_company/incremental_train_news.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_organization_company/incremental_train_broadcast.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:01<00:00, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_language/incremental_train_programming_language.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_health/incremental_train_treatment.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_health/incremental_train_malady.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_living_thing/incremental_train_animal.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_airport.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_hotel.json ...\n",
      "Type discarded\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_government.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_restaurant.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_hospital.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_sports_facility.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_structure/incremental_train_theater.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_violent_conflict.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_election.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:01<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_sports_event.json ...\n",
      "Type discarded\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_accident.json ...\n",
      "Type discarded\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_natural_disaster.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_protest.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_event/incremental_train_holiday.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_art/incremental_train_music.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_art/incremental_train_broadcast.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_art/incremental_train_film.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_art/incremental_train_stage.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_other_art/incremental_train_writing.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_geography/incremental_train_mountain.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_geography/incremental_train_body_of_water.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n",
      "Processing  /home/remote_hdd/datasets_for_incremental_training/ontonotes_shimaoka/complete/sons_of_location_geography/incremental_train_island.json ...\n",
      "Type kept\n",
      "Creating instance of the dataset for seed 0\n",
      "Creating instance of the dataset for seed 1\n",
      "Creating instance of the dataset for seed 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over incremental training dirs\n",
    "for dir in tqdm(os.listdir(SRC_DATA_DIR)):\n",
    "  dirpath_src = os.path.join(SRC_DATA_DIR, dir)\n",
    "  if os.path.isdir(dirpath_src):\n",
    "    # iterate over incremental training single partitions\n",
    "    for f in os.listdir(os.path.join(SRC_DATA_DIR, dir)):\n",
    "      filepath_src = os.path.join(dirpath_src, f)\n",
    "      print('Processing ', filepath_src, '...')\n",
    "      with open(filepath_src, 'r') as src:\n",
    "        lines = src.readlines()\n",
    "        # check frequency\n",
    "        if len(lines) >= MIN_FREQ:\n",
    "          print('Type kept')\n",
    "          # create an instance of the incremental dataset for each seed\n",
    "          for seed in SEED:\n",
    "            print('Creating instance of the dataset for seed', seed)\n",
    "            # prepare dir\n",
    "            dirpath_dst = os.path.join(DST_DATA_DIR.format(seed), dir)\n",
    "            if not os.path.exists(dirpath_dst):\n",
    "              os.makedirs(dirpath_dst, exist_ok=True)\n",
    "            \n",
    "            # save subset partitions\n",
    "            filepath_train_dst = os.path.join(dirpath_dst, f)\n",
    "            filepath_dev_dst = os.path.join(dirpath_dst, f.replace('_train_', '_dev_'))\n",
    "            with open(filepath_train_dst, 'w') as dst_train, open(filepath_dev_dst, 'w') as dst_dev:\n",
    "              # IMPORTANT: reset seed\n",
    "              random.seed(seed)\n",
    "              random.shuffle(lines)\n",
    "              idx_split = int(MIN_FREQ * TRAIN_RATIO)\n",
    "              train_lines = lines[:idx_split]\n",
    "              dev_lines = lines[-idx_split:]\n",
    "              # save\n",
    "              dst_train.writelines(train_lines)\n",
    "              dst_dev.writelines(dev_lines)\n",
    "        else:\n",
    "          print('Type discarded')\n",
    "        print()\n",
    "  else:\n",
    "    # copy other files\n",
    "    # shutil.copyfile(dirpath_src, os.path.join(DST_DATA_DIR, dir))\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('allennlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e9dcee44032020c09ec3581d25e14d5c935065f63f4e5d5ebaabcd7ccba5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
