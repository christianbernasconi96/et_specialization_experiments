{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create partitions for pretraining datasets and incremental datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../entity_typing_analysis/')\n",
    "import utils\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# set main directories\n",
    "DATA = 'few_NERD'\n",
    "TRAIN_DATA = 'train.json'\n",
    "DEV_DATA = 'dev.json'\n",
    "TEST_DATA = f\"test{'-12k' if DATA == 'bbn' else ''}.json\"\n",
    "SRC_DATA_DIR = f\"/home/remote_hdd/datasets/{DATA}\"\n",
    "DST_DATA_DIR = f'/home/remote_hdd/datasets_for_incremental_training/{DATA}/'\n",
    "ONTOLOGY_PATH = os.path.join(SRC_DATA_DIR, f\"all_types.txt\")\n",
    "if DATA == 'few_NERD':\n",
    "  ONTOLOGY_PATH = ONTOLOGY_PATH.replace('all_types.txt', 'all_types_with_fathers.txt')\n",
    "  SRC_DATA_DIR = SRC_DATA_DIR.replace(DATA, f'{DATA}/supervised_formatted')\n",
    "  TRAIN_DATA = 'train_with_fathers.json'\n",
    "  DEV_DATA = 'dev_with_fathers.json'\n",
    "\n",
    "MIN_TEST_FREQ = 30\n",
    "SEED = 1\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/art': 0,\n",
       " '/art/broadcastprogram': 1,\n",
       " '/art/film': 2,\n",
       " '/art/music': 3,\n",
       " '/art/other': 4,\n",
       " '/art/painting': 5,\n",
       " '/art/writtenart': 6,\n",
       " '/building': 7,\n",
       " '/building/airport': 8,\n",
       " '/building/hospital': 9,\n",
       " '/building/hotel': 10,\n",
       " '/building/library': 11,\n",
       " '/building/other': 12,\n",
       " '/building/restaurant': 13,\n",
       " '/building/sportsfacility': 14,\n",
       " '/building/theater': 15,\n",
       " '/event': 16,\n",
       " '/event/attack_battle_war_militaryconflict': 17,\n",
       " '/event/disaster': 18,\n",
       " '/event/election': 19,\n",
       " '/event/other': 20,\n",
       " '/event/protest': 21,\n",
       " '/event/sportsevent': 22,\n",
       " '/location': 23,\n",
       " '/location/GPE': 24,\n",
       " '/location/bodiesofwater': 25,\n",
       " '/location/island': 26,\n",
       " '/location/mountain': 27,\n",
       " '/location/other': 28,\n",
       " '/location/park': 29,\n",
       " '/location/road_railway_highway_transit': 30,\n",
       " '/organization': 31,\n",
       " '/organization/company': 32,\n",
       " '/organization/education': 33,\n",
       " '/organization/government_governmentagency': 34,\n",
       " '/organization/media_newspaper': 35,\n",
       " '/organization/other': 36,\n",
       " '/organization/politicalparty': 37,\n",
       " '/organization/religion': 38,\n",
       " '/organization/showorganization': 39,\n",
       " '/organization/sportsleague': 40,\n",
       " '/organization/sportsteam': 41,\n",
       " '/other': 42,\n",
       " '/other/astronomything': 43,\n",
       " '/other/award': 44,\n",
       " '/other/biologything': 45,\n",
       " '/other/chemicalthing': 46,\n",
       " '/other/currency': 47,\n",
       " '/other/disease': 48,\n",
       " '/other/educationaldegree': 49,\n",
       " '/other/god': 50,\n",
       " '/other/language': 51,\n",
       " '/other/law': 52,\n",
       " '/other/livingthing': 53,\n",
       " '/other/medical': 54,\n",
       " '/person': 55,\n",
       " '/person/actor': 56,\n",
       " '/person/artist_author': 57,\n",
       " '/person/athlete': 58,\n",
       " '/person/director': 59,\n",
       " '/person/other': 60,\n",
       " '/person/politician': 61,\n",
       " '/person/scholar': 62,\n",
       " '/person/soldier': 63,\n",
       " '/product': 64,\n",
       " '/product/airplane': 65,\n",
       " '/product/car': 66,\n",
       " '/product/food': 67,\n",
       " '/product/game': 68,\n",
       " '/product/other': 69,\n",
       " '/product/ship': 70,\n",
       " '/product/software': 71,\n",
       " '/product/train': 72,\n",
       " '/product/weapon': 73}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ontology\n",
    "type2id = utils.load_ontology(ONTOLOGY_PATH)\n",
    "types = list(type2id.keys())\n",
    "type2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340387/340387 [00:10<00:00, 32893.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/remote_hdd/datasets_for_incremental_training/few_NERD/all_types.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare paths\n",
    "src_train_path = os.path.join(SRC_DATA_DIR, TRAIN_DATA)\n",
    "dst_train_path = os.path.join(DST_DATA_DIR, TRAIN_DATA.replace('_with_fathers',''))\n",
    "dst_test_path = os.path.join(DST_DATA_DIR, TEST_DATA.replace('-12k',''))\n",
    "\n",
    "os.makedirs(DST_DATA_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(dst_train_path):\n",
    "    os.remove(dst_train_path)\n",
    "if os.path.exists(dst_test_path):\n",
    "    os.remove(dst_test_path)\n",
    "\n",
    "freq_test = defaultdict(int)\n",
    "\n",
    "# create train and test\n",
    "with open(src_train_path, 'r') as src_train, open(dst_train_path, 'a') as dst_train, open(dst_test_path, 'a') as dst_test:\n",
    "    lines = src_train.readlines()\n",
    "    random.Random(SEED).shuffle(lines)\n",
    "    for t in tqdm(lines):\n",
    "        # read example\n",
    "        example = json.loads(t)\n",
    "        labels = example['y_str']\n",
    "        # check labels\n",
    "        is_test = False\n",
    "        for label in labels:\n",
    "            # check if the example is needed by the test set\n",
    "            if freq_test[label] < MIN_TEST_FREQ:\n",
    "                # append example to the test set\n",
    "                dst_test.write(f'{json.dumps(example)}\\n')\n",
    "                # update counters\n",
    "                for label_ in labels:\n",
    "                    freq_test[label_] += 1\n",
    "                is_test = True\n",
    "                break\n",
    "        # append example to the training set\n",
    "        if not is_test:\n",
    "            dst_train.write(f'{json.dumps(example)}\\n')\n",
    "\n",
    "# copy ontology\n",
    "shutil.copy(ONTOLOGY_PATH, os.path.join(DST_DATA_DIR, 'all_types.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/location : 210\n",
      "/location/road_railway_highway_transit : 30\n",
      "/location/GPE : 30\n",
      "/product : 270\n",
      "/product/ship : 30\n",
      "/building : 240\n",
      "/building/other : 30\n",
      "/art : 180\n",
      "/art/film : 30\n",
      "/person : 240\n",
      "/person/politician : 30\n",
      "/other : 360\n",
      "/other/language : 30\n",
      "/product/train : 30\n",
      "/person/other : 30\n",
      "/location/island : 30\n",
      "/other/disease : 30\n",
      "/person/athlete : 30\n",
      "/art/music : 30\n",
      "/other/award : 30\n",
      "/product/software : 30\n",
      "/other/biologything : 30\n",
      "/product/airplane : 30\n",
      "/organization : 300\n",
      "/organization/sportsleague : 30\n",
      "/person/artist_author : 30\n",
      "/organization/other : 30\n",
      "/other/chemicalthing : 30\n",
      "/event : 180\n",
      "/event/sportsevent : 30\n",
      "/other/god : 30\n",
      "/other/astronomything : 30\n",
      "/organization/media_newspaper : 30\n",
      "/location/bodiesofwater : 30\n",
      "/art/writtenart : 30\n",
      "/organization/education : 30\n",
      "/building/sportsfacility : 30\n",
      "/location/other : 30\n",
      "/organization/sportsteam : 30\n",
      "/product/other : 30\n",
      "/person/actor : 30\n",
      "/location/mountain : 30\n",
      "/art/other : 30\n",
      "/organization/government_governmentagency : 30\n",
      "/other/livingthing : 30\n",
      "/product/car : 30\n",
      "/building/theater : 30\n",
      "/organization/company : 30\n",
      "/event/protest : 30\n",
      "/other/educationaldegree : 30\n",
      "/other/currency : 30\n",
      "/building/hospital : 30\n",
      "/person/soldier : 30\n",
      "/organization/politicalparty : 30\n",
      "/organization/showorganization : 30\n",
      "/organization/religion : 30\n",
      "/building/library : 30\n",
      "/art/painting : 30\n",
      "/event/other : 30\n",
      "/event/attack_battle_war_militaryconflict : 30\n",
      "/art/broadcastprogram : 30\n",
      "/person/director : 30\n",
      "/location/park : 30\n",
      "/building/airport : 30\n",
      "/building/hotel : 30\n",
      "/building/restaurant : 30\n",
      "/other/law : 30\n",
      "/product/weapon : 30\n",
      "/person/scholar : 30\n",
      "/product/food : 30\n",
      "/event/election : 30\n",
      "/product/game : 30\n",
      "/other/medical : 30\n",
      "/event/disaster : 30\n"
     ]
    }
   ],
   "source": [
    "for k,v in freq_test.items():\n",
    "  print(k,':',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('allennlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e9dcee44032020c09ec3581d25e14d5c935065f63f4e5d5ebaabcd7ccba5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
