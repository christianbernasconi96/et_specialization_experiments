{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create partitions for pretraining datasets and incremental datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../entity_typing_analysis/')\n",
    "import utils\n",
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# set main directories\n",
    "DATA = 'few_NERD'\n",
    "SCENARIO = 'complete' # ['complete', 'single_child']\n",
    "TRAIN_DATA = 'pretraining_train.json'\n",
    "DEV_DATA = 'pretraining_dev.json'\n",
    "TEST_DATA = f\"test.json\"\n",
    "SRC_DATA_DIR = f\"/home/remote_hdd/datasets_for_incremental_training/{DATA}/{SCENARIO}\"\n",
    "DST_DATA_DIR = f'/home/remote_hdd/datasets_for_incremental_training/{DATA}/{SCENARIO}'\n",
    "\n",
    "SEED = 1\n",
    "random.seed(1)\n",
    "\n",
    "N_DEV = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare paths\n",
    "src_train_path = os.path.join(SRC_DATA_DIR, TRAIN_DATA)\n",
    "dst_train_path = os.path.join(DST_DATA_DIR, TRAIN_DATA.replace('.json', '_nodev.json'))\n",
    "dst_dev_path = os.path.join(DST_DATA_DIR, DEV_DATA)\n",
    "\n",
    "if os.path.exists(dst_train_path):\n",
    "    os.remove(dst_train_path)\n",
    "if os.path.exists(dst_dev_path):\n",
    "    os.remove(dst_dev_path)\n",
    "\n",
    "os.makedirs(DST_DATA_DIR, exist_ok=True)\n",
    "\n",
    "with open(src_train_path, 'r') as src_train, open(dst_train_path, 'a') as dst_train, open(dst_dev_path, 'a') as dst_dev:\n",
    "    lines = src_train.readlines()\n",
    "    idx = N_DEV if type(N_DEV) == int else int(N_DEV * len(lines)) \n",
    "    # random sample\n",
    "    random.Random(SEED).shuffle(lines)\n",
    "    train_lines = lines[idx:]\n",
    "    dev_lines = lines[:idx]\n",
    "    dst_train.writelines(train_lines)\n",
    "    dst_dev.writelines(dev_lines)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('allennlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e9dcee44032020c09ec3581d25e14d5c935065f63f4e5d5ebaabcd7ccba5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
